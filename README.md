# ğŸ§  Neurolight Workbench

A powerful PySide6 desktop application for processing and analyzing large TIF image stacks with scientific rigor. Built for neuroscientists and researchers who need reproducible, shareable experiment workflows.

---

## âœ¨ Features

- ğŸ”¬ **Experiment-Centric Workflow** â€“ All work is organized into shareable experiment sessions
- ğŸ“¸ **High-Volume Image Processing** â€“ Handle 200+ TIF image stacks with ease
- ğŸ¨ **Intuitive Interface** â€“ Split-panel design with image navigation and analysis dashboard
- ğŸ”„ **Processing Pipeline** â€“ OpenCV integration with full history tracking
- ğŸ“Š **Scientific Analysis** â€“ Built on NumPy, SciPy, and Matplotlib
- ğŸ’¾ **Auto-Save** â€“ Never lose your work with periodic session saving
- ğŸ¤ **Collaboration Ready** â€“ Share experiments as portable JSON files

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.9 or higher
- [uv](https://github.com/astral-sh/uv) package manager

### Installation

1. **Install uv** (if not already installed)

   **Option A: Using pip (recommended)**
   
   ```bash
   Windows:
   pip install uv

   Mac:
   brew install uv
   ```

   **Option B: Official installer**

   ```bash
   # Windows (PowerShell)
   powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"

   # macOS/Linux
   curl -LsSf https://astral.sh/uv/install.sh | sh
   ```

3. **Clone or download the project**

   ```bash
   git clone https://github.com/Neuro-Light/neurolight-prototype
   cd neurolight-prototype
   ```

4. **Install dependencies and create virtual environment**

   ```bash
   uv sync
   ```

   This will automatically create a virtual environment (`.venv`) and install all dependencies into it.

5. **Launch the application**

   **Recommended: Use `uv run`** (automatically uses the virtual environment):

   ```bash
   uv run python src/main.py
   ```

   **Alternative: Manually activate the virtual environment**

   If you prefer to activate the venv yourself:

   **Windows:**

   ```bash
   .venv\Scripts\activate
   python src/main.py
   ```

   **macOS/Linux:**

   ```bash
   source .venv/bin/activate
   python src/main.py
   ```

---

## ğŸ“ Project Structure

```
neurolight-prototype/
â”‚
â”œâ”€â”€ ğŸ“„ README.md
â”œâ”€â”€ ğŸ“„ pyproject.toml
â”œâ”€â”€ ğŸ“„ requirements.txt
â”œâ”€â”€ ğŸ“„ .gitignore
â”‚
â”œâ”€â”€ ğŸ“‚ src/
â”‚   â”œâ”€â”€ main.py                    # Application entry point
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ ui/                     # User interface components
â”‚   â”‚   â”œâ”€â”€ startup_dialog.py     # Experiment selection screen
â”‚   â”‚   â”œâ”€â”€ main_window.py        # Main application window
â”‚   â”‚   â”œâ”€â”€ image_viewer.py       # Image display & navigation
â”‚   â”‚   â””â”€â”€ analysis_panel.py     # Analysis dashboard
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ core/                   # Core functionality
â”‚   â”‚   â”œâ”€â”€ experiment_manager.py # Experiment session handling
â”‚   â”‚   â”œâ”€â”€ image_processor.py    # OpenCV processing pipeline
â”‚   â”‚   â”œâ”€â”€ gif_generator.py      # Animation export
â”‚   â”‚   â””â”€â”€ data_analyzer.py      # Statistical analysis
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“‚ utils/                  # Utilities
â”‚       â””â”€â”€ file_handler.py       # TIF stack I/O
â”‚
â”œâ”€â”€ ğŸ“‚ experiments/                # Default experiment storage
â”œâ”€â”€ ğŸ“‚ assets/
â”‚   â””â”€â”€ ğŸ“‚ icons/
â””â”€â”€ ğŸ“‚ tests/                      # Unit tests (placeholder)
```

### ğŸ”§ Module Responsibilities

| Module                    | Purpose                                                                                  |
| ------------------------- | ---------------------------------------------------------------------------------------- |
| **experiment_manager.py** | Create, load, save `.nexp` experiments; manage recent experiments list                   |
| **file_handler.py**       | Load/validate TIF stacks; provide random frame access; associate stacks with experiments |
| **image_processor.py**    | Apply OpenCV operations; maintain processing history for reproducibility                 |
| **gif_generator.py**      | Generate and optimize animated GIFs from image sequences                                 |
| **data_analyzer.py**      | Calculate statistics, generate plots; store results in experiment sessions               |
| **startup_dialog.py**     | Present new/load experiment options; show recent experiments                             |
| **main_window.py**        | Coordinate menus, panels, and auto-save functionality                                    |
| **image_viewer.py**       | Display TIFs with navigation controls; implement LRU caching; handle drag-and-drop       |
| **analysis_panel.py**     | Provide tabbed interface for future analysis tools                                       |

---

## ğŸ”¬ Experiment Workflow

### What is an Experiment?

An **experiment** is a complete research session stored as a JSON file (`.nexp`) containing:

- ğŸ“‹ Metadata (name, description, principal investigator, dates)
- ğŸ–¼ï¸ Image stack information (path, dimensions, bit depth)
- âš™ï¸ Processing history (all operations and parameters)
- ğŸ“ˆ Analysis results (statistics, plots)
- ğŸ›ï¸ Custom settings

### Experiment File Format (v1.0)

```json
{
  "version": "1.0",
  "experiment": {
    "name": "Cortical Response Study 001",
    "description": "Analysis of cortical neurons under stimulation",
    "principal_investigator": "Dr. Jane Smith",
    "created_date": "2025-10-30T10:30:00",
    "modified_date": "2025-10-30T14:45:00",
    "image_stack": {
      "path": "/path/to/images/",
      "file_list": ["image001.tif", "image002.tif"],
      "count": 200,
      "format": "tif",
      "dimensions": [1024, 1024],
      "bit_depth": 16
    },
    "processing": {
      "history": [...]
    },
    "analysis": {
      "results": {}
    },
    "settings": {}
  }
}
```

### Sharing Experiments

To collaborate with colleagues:

1. Export the `.nexp` file from your `experiments/` directory
2. Include the referenced image stack folder
3. Colleagues can load the experiment and reproduce your entire workflow

**Note:** Both the `.nexp` file and the image stack folder must be shared; the experiment file references image paths, so the folder structure should be preserved when sharing.

---

## ğŸ“– Usage Guide

### Starting the Application

**Launch Screen:**

1. Application opens to the **Startup Dialog**
2. Choose your path:
   - ğŸ†• **Start New Experiment** â€“ Enter metadata and create a fresh session
   - ğŸ“‚ **Load Existing Experiment** â€“ Browse for an existing `.nexp` file
   - ğŸ•’ **Recent Experiments** â€“ Quick access to your last 5 experiments

### Working with Experiments

**Creating a New Experiment:**

- Provide experiment name (required)
- Add description and principal investigator
- Choose save location (defaults to `experiments/` directory)
- Click **Create** to begin

**Main Application Window:**

**Left Panel** (Image Navigation):

- Drag-and-drop TIF files or an entire folder
- Navigate frames with **Previous/Next** buttons
- Use the slider for quick jumping
- Frame counter displays current position

**Right Panel** (Analysis Dashboard):

- Tabbed interface with placeholders for:
  - ğŸ“Š Statistics
  - ğŸ“ˆ Graphs
  - ğŸ¯ Detection (YOLOv8 integration planned)

**Menu Bar:**

- **File**: Save, Save As, Close Experiment, Open Image Stack, Export, Exit
- **Edit**: Experiment Settings (edit metadata)
- **Tools**: Generate GIF, Run Analysis (coming soon)
- **Help**: About

### Recent Experiments

Recent experiments are tracked in `~/.neurolight/recent_experiments.json` and display:

- Experiment name
- Last modified date
- Full file path

Double-click any recent experiment to load it instantly.

---

## ğŸ—ï¸ Architecture

### Design Principles

- **ğŸ§© Modularity** â€“ Independent, replaceable components
- **ğŸ”Œ Extensibility** â€“ Clear interfaces for adding new features
- **ğŸ’¼ Session Management** â€“ All actions tied to experiment context
- **âš¡ Performance** â€“ Lazy loading, background threads, progress feedback
- **ğŸ›¡ï¸ Error Handling** â€“ Graceful failures with user-friendly messages

### Performance Features

- **Lazy Image Loading** â€“ Images loaded on-demand, not all at once
- **LRU Cache** â€“ Keeps ~20 recently viewed images in memory
- **Background Processing** â€“ Long operations don't freeze the UI
- **Auto-Save** â€“ Periodic background saves (configurable)

### Application Flow

```
Launch â†’ Startup Dialog â†’ Create/Load Experiment â†’ Main Window â†’ Auto-Save Loop
```

---

## ğŸ§ª Testing

### Framework

We recommend **pytest** for unit and integration testing.

### Test Structure

```
tests/
â”œâ”€â”€ test_experiment_manager.py
â”œâ”€â”€ test_file_handler.py
â”œâ”€â”€ test_image_processor.py
â””â”€â”€ test_ui_components.py
```

### Running Tests

```bash
uv sync --all-extras  # Install with test dependencies
pytest tests/
```

---

## ğŸš§ Future Roadmap

### Planned Features

**Collaboration & Sharing:**

- ğŸ”„ Experiment versioning and history
- â˜ï¸ Cloud storage integration
- ğŸ¤ Multi-user experiment comparison tools
- ğŸ“¤ Export to standardized formats (HDF5, OME-TIFF)

**Advanced Analysis:**

- ğŸ¯ YOLOv8 object detection integration
- âš™ï¸ Real-time processing pipelines
- ğŸ“Š Advanced statistical modeling (statsmodels)
- ğŸ”¬ Custom filter creation interface

**User Experience:**

- ğŸŒ™ Dark mode support
- ğŸ“¦ Batch processing capabilities
- ğŸ¨ Custom themes and layouts
- ğŸ“‹ Experiment templates for common workflows

---

## ğŸ¤ Contributing

Areas for improvement:

- Additional image processing algorithms
- New analysis visualizations
- UI/UX enhancements
- Documentation improvements
- Bug reports and feature requests

---

## ğŸ“ License

MIT

---

## ğŸ™ Acknowledgments

Built with:

- [PySide6](https://doc.qt.io/qtforpython/) â€“ Qt for Python
- [OpenCV](https://opencv.org/) â€“ Computer vision library
- [NumPy](https://numpy.org/) / [SciPy](https://scipy.org/) â€“ Scientific computing
- [Matplotlib](https://matplotlib.org/) â€“ Plotting and visualization
- [YOLOv8](https://github.com/ultralytics/ultralytics) â€“ Object detection (planned)

---

<div align="center">

**Made with ğŸ§  for neuroscience research**

</div>
